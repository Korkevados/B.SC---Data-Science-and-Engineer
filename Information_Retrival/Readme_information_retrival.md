<!-- @format -->

# Project Descriptions

## Assignment 1: Wikipedia Parser & Tokenizer

This project involves building a parser and tokenizer for Wikipedia content.  
It extracts and processes text efficiently, preparing it for further natural language processing tasks.  
The implementation focuses on handling Wikipedia's specific formatting and structures.  
The project is essential for text-based applications like indexing and search engines.

## Assignment 2: Indexing

The project focuses on developing an efficient indexing system for large-scale text data.  
It includes building an inverted index and optimizing search performance.  
The indexing techniques improve query response time and storage efficiency.  
The project is a core component of information retrieval systems.

## Assignment 3: MapReduce & Web Graph

This project applies the MapReduce paradigm to process web graphs at scale.  
It focuses on distributed computing techniques to analyze link structures and page relationships.  
The implementation is optimized for cloud-based environments like Google Colab.  
The project is fundamental for large-scale data processing in distributed systems.

## Assignment 4: Ranking & Evaluation

This project implements ranking algorithms to improve search result relevance.  
It includes evaluating different ranking techniques using standard metrics.  
The approach enhances information retrieval accuracy and user satisfaction.  
The project is crucial for optimizing search engines and recommendation systems.

## GCP Notebook - Execution Guidelines

This notebook contains essential configurations and must retain its execution output.  
It includes predefined setups for running computations on Google Cloud.  
The project ensures smooth execution of large-scale data processing tasks.  
Users should not clear the outputs to maintain execution integrity.
